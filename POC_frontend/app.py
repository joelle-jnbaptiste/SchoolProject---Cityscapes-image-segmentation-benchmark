from metric_info import metric_info
import plotly.express as px
import pandas as pd
from mlflow.tracking import MlflowClient
import mlflow
import io
import base64
import streamlit as st
import requests
from PIL import Image

# -------------------------------------------------------------------
# CONFIG ‚Äî ACCESSIBILIT√â
# -------------------------------------------------------------------
st.set_page_config(
    page_title="Comparaison Segmentation ‚Äì DeepLab vs Mask2Former",
    layout="wide"
)


PRIMARY_COLOR = "#003566"   
SECONDARY_COLOR = "#f1f1f1"  

# -------------------------------------------------------------------
# TITRE + INTRO
# -------------------------------------------------------------------

st.header("Preuve de Concept : Segmentation d‚Äôimages avec DeepLabV3+ et Mask2Former")

st.markdown("""
### Dataset : Cityscapes (version r√©duite √† 8 classes)

Ce projet utilise une version simplifi√©e du dataset **Cityscapes**, largement utilis√© 
pour la recherche en **segmentation d‚Äôimages dans les syst√®mes de conduite autonome**.

Les images proviennent de sc√®nes urbaines (Allemagne) captur√©es depuis un v√©hicule,  
et chaque image poss√®de un **masque s√©mantique** o√π chaque pixel correspond √† une classe.

Nous utilisons ici une version regroup√©e du dataset, limit√©e √† **8 grandes cat√©gories** :
""")

# --- Classes ---
st.markdown("""
#### Les 8 classes retenues
- **flat** ‚Äî route, trottoir  
- **human** ‚Äî pi√©tons  
- **vehicle** ‚Äî voitures, bus, camions  
- **construction** ‚Äî b√¢timents, structures  
- **object** ‚Äî panneaux, barri√®res, poteaux  
- **nature** ‚Äî v√©g√©tation, arbres  
- **sky** ‚Äî ciel  
- **void** ‚Äî pixels ignor√©s ou non pertinents  
""")

# --- R√©partition ---
st.markdown("""
## R√©partition du dataset

Deux configurations ont √©t√© utilis√©es pour analyser le comportement des mod√®les :

- **Train : 300** images &nbsp; | &nbsp; **Val : 50** images  
- **Train : 2975** images &nbsp; | &nbsp; **Val : 500** images  

La premi√®re (300/50) sert √† tester l‚Äôapprentissage avec peu de donn√©es.  
La seconde (2975/500) permet d‚Äô√©valuer les mod√®les √† plus grande √©chelle.
""")

# --- Exemple image + masque ---
st.markdown("""
## Exemple d‚Äôimage et masque de v√©rit√© terrain (GT)

Voici un exemple permettant de visualiser ce √† quoi ressemblent les donn√©es utilis√©es
pour l‚Äôentra√Ænement du mod√®le.
""")

img = Image.open("img/masque.png")
st.image(img, use_container_width=True)
st.markdown(
    "<p aria-label='Image segment√©e DeepLab, chaque couleur repr√©sente une classe du masque s√©mantique.'></p>",
    unsafe_allow_html=True
)


# --- Entra√Ænement ---
st.markdown("""
### Br√®ve description de l‚Äôentra√Ænement

Chaque mod√®le apprend √† pr√©dire, pour **chaque pixel**, la classe correcte parmi 8 cat√©gories.

L‚Äôentra√Ænement suit les √©tapes suivantes :

1. **Pr√©traitement** : redimensionnement, normalisation, encodage des masques.  
2. **Architecture du mod√®le** :  
   - **DeepLabV3+ (ResNet50)** ‚Äî CNN avec d√©codeur dilat√©, rapide et stable  
   - **Mask2Former** ‚Äî architecture transformer moderne, tr√®s performante  
3. **Suivi des m√©triques** :  
    - mIoU
    - pixel accuracy
    - pertes
    - vitesse  
4. **Validation** :  
   - le mod√®le est test√© sur un jeu **jamais vu**  
   - comparaison syst√©matique DeepLabV3+ vs Mask2Former sur 10 epochs  

L‚Äôobjectif final du projet est de comparer la performance et l‚Äôefficacit√© des deux mod√®les.
""")


st.markdown("---")

# -------------------------------------------------------------------
# SECTION : GRAPHIQUES DES R√âSULTATS
# -------------------------------------------------------------------


client = MlflowClient()

DEEPLAB_RUN_ID = "9d1d6201075647d088840506a93f7a3f"
MASK2F_RUN_ID = "e07ee9aa361c469a929e2db5cfeeb029" 


def get_metric_df(run_id, metric_name):
    history = client.get_metric_history(run_id, metric_name)
    df = pd.DataFrame({
        "step": [m.step for m in history],
        metric_name: [m.value for m in history]
    })
    return df


def plot_metric(run_id, metric, title):
    df = get_metric_df(run_id, metric)
    fig = px.line(df, x="step", y=metric, title=title)
    fig.update_layout(
        template="plotly_white",
        title_font_size=18,
        xaxis_title="Step",
        yaxis_title=metric,
    )
    return fig


def get_combined_metric(run_id_A, run_id_B, metric_name, name_A="DeepLabV3+", name_B="Mask2Former"):
    # DeepLab
    hist_A = client.get_metric_history(run_id_A, metric_name)
    df_A = pd.DataFrame({
        "step": [m.step for m in hist_A],
        "value": [m.value for m in hist_A],
        "model": name_A
    })

    # Mask2Former
    hist_B = client.get_metric_history(run_id_B, metric_name)
    df_B = pd.DataFrame({
        "step": [m.step for m in hist_B],
        "value": [m.value for m in hist_B],
        "model": name_B
    })

    return pd.concat([df_A, df_B], axis=0)


def plot_comparison(df, metric_name):
    fig = px.line(
        df,
        x="step",
        y="value",
        color="model",
        title=f"Comparaison {metric_name} ‚Äî DeepLabV3+ vs Mask2Former",
        markers=False
    )

    fig.update_layout(
        template="plotly_white",
        title_font_size=20,
        xaxis_title="Step",
        yaxis_title=metric_name,
        legend_title="Mod√®le",
        height=500
    )

    fig.update_traces(
        selector=dict(name="DeepLabV3+"),
        line=dict(color="#003566")  
    )

    fig.update_traces(
        selector=dict(name="Mask2Former"),
        line=dict(color="#D62828") 
    )

    return fig

st.markdown("""## Comparaison des mod√®les sur les m√©triques cl√©s""")

metric = st.selectbox(
    "S√©lectionnez une m√©trique √† comparer :",
    ["train_loss", "val_loss", "miou", "pixel_acc", "imgs_per_sec", "train_time_sec"]
)

df_metric = get_combined_metric(DEEPLAB_RUN_ID, MASK2F_RUN_ID, metric)
fig = plot_comparison(df_metric, metric)


col1, col2 = st.columns([3, 2])  

with col1:
    st.markdown(f"## {metric_info[metric]['title']}")
    st.plotly_chart(fig, use_container_width=True)
        # Description alternative pour lecteurs d‚Äô√©cran
    st.markdown(
        f"""
        <div role="doc-subtitle" aria-label="R√©sum√© textuel du graphique {metric}">
        <p><strong>Description alternative (accessibilit√©) :</strong></p>
        <p>{metric_info[metric]["alt_text"]}</p>
        </div>
        """, unsafe_allow_html=True
    )

with col2:
    st.markdown(metric_info[metric]["description"])
    st.markdown(metric_info[metric]["comparison"])


st.markdown("---")

# -------------------------------------------------------------------
# SECTION : APPEL API + PR√âDICTIONS
# -------------------------------------------------------------------
st.markdown("""## Tester les mod√®les sur une nouvelle image""")


import streamlit as st
from PIL import Image

CITYSCAPES_COLORS_BACKEND = {
    "flat":        (128, 64, 128),
    "human":       (244, 35, 232),
    "vehicle":     (70, 70, 70),
    "construction":(102, 102, 156),
    "object":      (190, 153, 153),
    "nature":      (153, 153, 153),
    "sky":         (250, 170, 30),
    "void":        (220, 220, 0),
}

CITYSCAPES_LABELS_FR = {
    "flat": "Surfaces planes (routes, trottoirs)",
    "human": "Personnes (pi√©tons, silhouettes)",
    "vehicle": "V√©hicules (voitures, bus, motos‚Ä¶)",
    "construction": "√âl√©ments de construction (b√¢timents, murs)",
    "object": "Objets urbains (poteaux, panneaux‚Ä¶)",
    "nature": "Nature (arbres, herbes, v√©g√©tation)",
    "sky": "Ciel",
    "void": "R√©gions non pertinentes / inconnues",
}

st.markdown("#### L√©gende des classes")

cols = st.columns(4)
i = 0
for key, rgb in CITYSCAPES_COLORS_BACKEND.items():
    img = Image.new("RGB", (40, 40), rgb)
    with cols[i % 4]:
        st.image(img, width=40)
        st.markdown(f"**{key.capitalize()}**  \n*{CITYSCAPES_LABELS_FR[key]}*")
    i += 1

st.markdown("---")



uploaded_file = st.file_uploader(
    "S√©lectionnez une image (JPEG/PNG)",
    type=["jpg", "png"],
    help="T√©l√©verser une image entre 100√ó100 et 2000√ó2000 px. Compatible JPG/PNG. Taille maximale 200 Mo."
)

API_URL = "http://18.234.222.127:8000/predict"
#API_URL = "http://127.0.0.1:8000//predict"


def decode_base64_image(data_url: str) -> Image.Image:
    header, encoded = data_url.split(",", 1)
    data = base64.b64decode(encoded)
    return Image.open(io.BytesIO(data))


# -------------------------------------------------------------------
# ENVOI √Ä L'API
# -------------------------------------------------------------------
if uploaded_file is not None:
    st.markdown("### üì° Envoi de l'image √† l'API‚Ä¶")

    files = {
        "image": (uploaded_file.name, uploaded_file.getvalue(), uploaded_file.type)
    }

    try:
        response = requests.post(API_URL, files=files, timeout=20)

        if response.status_code != 200:
            st.error(
                f"Erreur API : impossible d'obtenir une pr√©diction. (Code {response.status_code})")

        else:
            results = response.json()
            col1, col2 = st.columns(2)

            # -----------------------------------
            # DeepLab
            # -----------------------------------
            with col1:
                st.markdown("### DeepLabV3+ ‚Äì R√©sultat")

                deeplab_img = decode_base64_image(results["deeplab_png"])
                st.image(
                    deeplab_img,
                    use_container_width=True,
                    caption="Pr√©diction DeepLab ‚Äì Masque segment√©"
                )

            # -----------------------------------
            # Mask2Former
            # -----------------------------------
            with col2:
                st.markdown("### Mask2Former ‚Äì R√©sultat")

                mask2former_img = decode_base64_image(
                    results["mask2former_png"])
                st.image(
                    mask2former_img,
                    use_container_width=True,
                    caption="Pr√©diction Mask2Former ‚Äì Masque segment√©"
                )

    except Exception as e:
        st.error(f"Erreur lors de l'appel API : {e}")
